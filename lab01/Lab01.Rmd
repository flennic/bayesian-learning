---
title: "Bayesian Learning - Lab 01"
author: "Lakshidaa Saigiridharan (laksa656) and Maximilian Pfundstein (maxpf364)"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: false
    number_sections: false
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(geoR)
```

# Bernoulli

## Drawing from the Posterior

First we define the parameters as we need them later.

```{r}

################################################################################
# Exercise 1
################################################################################

# Parameters
n = 20
s = 14
f = n - s

# Prior
alpha_z = 2
beta_z = 2

# Posterior
alpha_post = alpha_z + s
beta_post = beta_z + f

```

The posterior is given as Beta($\alpha_n$, $\beta_n$) where $\alpha_n = \alpha_0 + s$ and $\beta_n = \beta_0 + f$. Therefore the theoretical mean is given by:

$$\text{E}[X] = \frac{\alpha_n}{\alpha_n + \beta_n}$$
And the standard deviation by:

$$\text{sd}[X] = \sqrt{\frac{\alpha_n \beta_n}{(\alpha_n + \beta_n)^2(\alpha_n + \beta_n + 1)}}$$

So let's calculate this.

```{r}

mean_posterior = alpha_post / (alpha_post + beta_post)
sd_posterior = sqrt((alpha_post * beta_post) /
                  ((alpha_post + beta_post)^2 * (alpha_post + beta_post + 1))) 

```

Therefore the mean of the prior is given by $`r mean_posterior`$ and the standard deviation by $`r sd_posterior`$.

Now we will create a function that calculates the mean and standard deviation for a given number of trials to plot it later on.

```{r}

get_stats = function(n, alpha, beta) {
  samples = rbeta(n, alpha, beta)
  return(c(count = n, sample_mean = mean(samples), sample_sd = sd(samples)))
}

df = data.frame(t(sapply(2:10000, get_stats, alpha_post, beta_post)))

```

```{r, echo = FALSE}

ggplot(df) +
  geom_line(aes(x = count, y = sample_mean, color = "Standard Mean")) +
  geom_line(aes(x = count, y = mean_posterior, color = "True Mean")) +
  labs(title = "Mean with Increasing Drawns", y = "Mean", x = "Draws") +
  scale_color_manual("Legend", values = c("#C70039", "#000000")) +
  theme_minimal()

```

```{r, echo = FALSE}

ggplot(df) +
  geom_line(aes(x = count, y = sample_sd, colour = "Standard Deviation")) +
  geom_line(aes(x = count, y = sd_posterior, colour = "True Standard Deviation")) +
  labs(title = " Standard Deviation with Increasing Drawns",
       y = "Standard Deviation", x = "Draws") +
  scale_color_manual("Legend", values = c("#0039C7", "#000000")) +
  theme_minimal()

```

## $Pr(\theta < 0.4 | y)$

The true probability is given by `pbeta(0.4, alpha_post, beta_post)` which is `r pbeta(0.4, alpha_post, beta_post)`.

We will simulate by taking samples and counting how many of them are < $0.4$.

```{r}

mean(rbeta(100000, alpha_post, beta_post) < 0.4)

```

As we can see both values are quite close to each other.

## Log-Odds

The log-odds are given by

$$\Phi = \text{log} \left( \frac{\theta}{1 - \theta} \right)$$
where $\theta$ are samples drawn from the posterior. We can therefore easily calculate the value by:

```{r}

draws = 10000

samples = rbeta(draws, alpha_post, beta_post)
phi = data.frame(log(samples / (1 - samples)))
colnames(phi) = "phi"

```

```{r, echo = FALSE}

ggplot(phi) +
  geom_histogram(aes(x = phi, y=..density..), color = "black",
                 fill = "#dedede", bins = sqrt(draws)) +
  labs(title = "Histrogram of Log-Odds",
  y = "Density",
  x = "Log-Odds", color = "Legend") +
  theme_minimal()

```


# Log-Normal Distribution and the Gini Coefficient

## Simulate Draws from the Posterior Distribution

```{r}

#rinvchisq = function(n, df, tau_sq) {
#  return(df * tau_sq / rchisq(n, df))
#}

obs = c(14, 25, 45, 25, 30, 33, 19, 50, 34, 67)
n = length(obs)
mu = 3.5
tau_sq = (sum((log(obs) - mu)^2)) / (n)

samples = rinvchisq(10000, n, tau_sq)
X = seq(from = 0, to = 4, length.out = 1000)
Y = dinvchisq(X, n, tau_sq)

df = data.frame(X, Y)
samples_df = data.frame(samples)

```

```{r, echo = FALSE, warning = FALSE}

ggplot(df) +
  geom_histogram(data = samples_df, aes(x = samples, y=..density..),
                 bins = sqrt(nrow(samples_df)), color = "black", fill = "#DEDEDE") +
  geom_line(aes(x = X, y = Y, color = "Density Function")) +
  labs(title = "Drawn Samples and Inverse-Chi-Squared Density Function", y = "Density", x = "X") +
  scale_color_manual("Legend", values = c("#0039C7", "#000000")) +
  theme_minimal()

```

## Gini-Index

```{r}

#g = function(q, mu, sd) {
#  return(2 * pnorm(q, mean = mu, sd = (sd/sqrt(2)) - 1))
#}

G = 2 * pnorm(sqrt(samples/2)) - 1

#sapply(samples, g, mu = mu, sd = samples)

```

```{r, echo = FALSE}

G_df = data.frame(G)

ggplot(G_df) +
  geom_histogram(aes(x = G, y=..density..),
                 bins = sqrt(nrow(G_df)), color = "black", fill = "#DEDEDE") +
  labs(title = "Gini Index of the Drawn Inverse Chi-Squared Samples",
       y = "Density", x = "X") +
  scale_color_manual("Legend", values = c("#0039C7", "#000000")) +
  theme_minimal()

```

## Credible and Density Interval

```{r}

quantiles = quantile(G, c(0.025, 0.975))

```

```{r, echo = FALSE}

ggplot(G_df) +
  annotate("rect", xmin=quantiles[1], xmax=quantiles[2], ymin=0, ymax=Inf,
           alpha=0.5, fill="#FFC300") +
  geom_histogram(aes(x = G, y=..density..),
                 bins = sqrt(nrow(G_df)), color = "black", fill = "#DEDEDE") +
  geom_vline(xintercept = quantiles, colour = "#FFC300") + 
  labs(title = "Two Tailed 95% Credible Interval",
       y = "Density", x = "X") +
  scale_color_manual("Legend", values = c("#0039C7", "#000000")) +
  theme_minimal()
```

```{r}

dg = density(G)

dg_unordered = data.frame(dg$x, dg$y)
dg_ordered = data.frame(dg$x[order(dg$y)], dg$y[order(dg$y)])
colnames(dg_ordered) = c("x_ord", "y_ord")

index = NaN

for (i in 1:nrow(dg_ordered)) {
  if (sum(dg_ordered$y_ord[1:i])/sum(dg_ordered$y_ord) > 0.05) {
    index = i
    break
  }
}

theta = dg_ordered[index,2]
print(theta)

selected = dg_unordered[dg_unordered$dg.y > theta,]

interval_a = selected[1,]
interval_b = selected[nrow(selected),]

```

```{r, echo = FALSE}

dg_df = data.frame(dg$x, dg$y)

ggplot(dg_df) +
  geom_line(aes(x = dg.x, y = dg.y, color = "Density Function")) +
  labs(title = "Gini Index of the Drawn Inverse Chi-Squared Samples",
       y = "Density", x = "X") +
  #geom_vline(xintercept = c(interval_a$dg.x, interval_b$dg.x), colour = "#0039C7") +
  geom_ribbon(data = selected, aes(x = dg.x, ymin = 0, ymax = dg.y),
              alpha = 0.5, fill = "#FFC300", color = "#FFC300") + 
  scale_color_manual("Legend", values = c("#000000", "#000000")) +
  theme_minimal()
#0039C7
```

# Bayesian Inference

# Source Code

```{r, ref.label=knitr::all_labels(), echo = TRUE, eval = FALSE, results = 'show'}

```